{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 5\n",
    "Please follow the directions below, in which you will extract data from an off-line source and migrate it into a normalized SQLite database. Points will be awarded as indicated. Note: later steps depend on earlier steps, so you should check your work as you go along.\n",
    "\n",
    "__All required cells have been provided. You only need to edit the ones that have placeholder phrases like YOUR CODE HERE.__\n",
    "\n",
    "This quiz is open book. You may use whatever documentation you like (even Google or past assignments in the course) but **you may not consult another person during the quiz** without the instructor's permission. That includes sharing code with your classmates, which is obviously not allowed. \n",
    "\n",
    "__Finally, use comments to document what you are doing with each block of code. Poorly documented code will be penalized accordingly.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (4 points) Import/Load all required packages.\n",
    "Import `pandas`, `sqlite3`, and the `parse_course_spec()` function from [`coursedata-util.py`](coursedata_util.py). (Hint: you may want to take a look at how we imported custom module code in the Movies Tonight Part 5 demo.) Then load the `sql` Jupyter extention needed for `%sql` magic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "YOUR CODE HERE\n",
    "Turning in assignment for minimal credit (0 or 1), electing to drop quiz 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (1 point) Create a SQLite database named `FairfieldCoursesFall2017.db`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (8 points) Study the source data and design your database.\n",
    "The [`CourseScheduleScrape.txt` file](CourseScheduleScrape.txt) located in this folder was *scraped* directly from the PDF of the [Fall 2016 Schedule of Courses](Fall2015_course_booklet.pdf) booklet. The code cell below *parses* each line of the file into a `list` of `dict`s called `course_specs`. The result looks a lot like [JSON-formatted data](https://www.ibm.com/support/knowledgecenter/en/STXNRM_3.10.2/coss.doc/managerapi1128.html) commonly returned by ReSTful web services. You will need to extract the data into tables in a SQLite database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "course_specs = []\n",
    "for spec in open(\"CourseScheduleScrape.txt\").read().splitlines():\n",
    "    course_specs.append(parse_course_spec(spec))\n",
    "course_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how the data looks like as a single denormalized table, we'll use Pandas's built-in JSON formatting library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "from pandas.io.json import json_normalize\n",
    "json_normalize(course_specs).set_index('CRN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your interpretation of the data, **write out the table schema** in **TABLENAME(<u>PK</u>, Attributes, *FK*)** notation. Each PK should be underlined. Each FK should be italics, and the other columns should be plain text. Please list one table per line.  \n",
    "\n",
    "Hints:\n",
    "* To see how to underline and italicize in Markdown, just double-click this cell. <!-- You can mix HTML in with Markdown, so underlining is just a <u>...</u> element. -->\n",
    "* To force text to appear on a new line you can either use two spaces at the end of the line above<!-- or use an HTML `<br>` tag -->.\n",
    "* You can answer this question with just four tables.\n",
    "* Two sections with the same CatalogID can have different titles (e.g., for EN11), so treat the titles as section-specific.\n",
    "* Credits are specified in the course catalog. They are sometimes are given as a range (e.g., 1-3) instead of as integers, so you may want to use a string.\n",
    "* Items in the table above that look like lists **are** lists and need to handled as such. \n",
    "* There is a reason why `CRN` was chosen as the index to the DataFrame.\n",
    "* Since the only data you have for each faculty member is a name, just treat the instructor names as value objects.\n",
    "* You may add surrogate keys if you like, but it's not strictly necessary if you use composite keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (8 points) Write DDL to create your tables (with keys) in the database. \n",
    "Suggestions: \n",
    "* Use `%%sql` so you can do this on one cell. \n",
    "* Use DROP TABLE IF EXISTS for each table before creating it. You've seen this done in a couple of demos so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (up to 8 points) Assemble the data into lists of dicts. \n",
    "Each table in your design is a list. Each record in the table is then a dictionary, with the column names as the keys.\n",
    "\n",
    "There are two approaches you can take:\n",
    "1. (4 points) Construct the lists (and nested dictionaries) by hand. Each list needs to have at least 5 records and cannot violate referential integrity rules. \n",
    "2. (8 points) Extract the data by [Traversing](https://en.wikipedia.org/wiki/Tree_traversal) the `course_specs` tree. Here's a bit of pseudocode for the basic logic:  \n",
    "\n",
    "```\n",
    "initialize an empty set for each table in your design\n",
    "for each dict or list at level 1 of the course_specs tree:  \n",
    "    add records (one or more dicts) to relevant sets\n",
    "    note values that represent PKs\n",
    "    for each dict or list found at level 2:\n",
    "        add records (one or more dicts) to relevant sets \n",
    "        note values that represent PKs\n",
    "        for each dict or list found at level 3:\n",
    "            ...\n",
    "```   \n",
    "Traversal Notes:\n",
    "* With each level you still have access to data in the level above. That allows you to set FKs as needed.\n",
    "* The easiest way to add `a_dict` to `a_list` is with `a_list += [a_dict]`.\n",
    "* Before adding `a_dict` to `a_list` you should make sure it is not already in the list. You can do that with `if a_dict not in a_list: ...` \n",
    "* List for strong entities will *tend* to be populated in level 1, children in level 2, grandchildren in level 3, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (4 points)  Convert your lists to DataFrames.\n",
    "Again, that's one DataFrame per list of dicts. Name the DataFrames to match the table names. Use One cell per DataFrame and display the table at the bottom of the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR CODE FOR TABLE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR CODE FOR TABLE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR CODE FOR TABLE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR CODE FOR TABLE 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (6 points) Write your DataFrames to the database. \n",
    "* Use the [DataFrame.to_sql() method](https://pandas.pydata.org/pandas-docs/stable/io.html#sql-queries) to write to the database. You will need to set the `if_exists` and (possibly) the `index` arguments when calling `.to_sql()`. \n",
    "* You will also need a sqlite3 connection. \n",
    "* A few relevant examples were given towards the end in the SQLite DDL and Migration Demo.\n",
    "* Provide a SQL SELECT query that joins your tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR DATAFRAME CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR %SQL CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7. (1 point) Turn your work to GitHub.\n",
    "Commit your work in Git, then push your changes to GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
